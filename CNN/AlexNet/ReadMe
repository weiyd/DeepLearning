1、使用Relu解决了梯度弥散问题
2、使用Dropout避免模型过拟合
3、使用重叠的最大池化，取代之前的平均池化，避免了平均池化引起的模糊效果
4、提出了LRN层，使神经元具有竞争机制，响应大的值变得相对更大，响应小的值变得相对更小
5、数据增强，256x256截取224x224，得到(256-224)^2x2倍数据量，防止过拟合，提高泛化能力预测时候，一张图片采用四个角和中间以及翻转得到的图片进行预测，10倍测试数据
6、使用CUDA进行加速训练模型
